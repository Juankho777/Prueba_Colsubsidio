# Configuración de Parámetros del Modelo - Colsubsidio Churn Prediction
# Este archivo centraliza todos los parámetros para evitar hardcoding

# =============================================================================
# CONFIGURACIÓN GENERAL
# =============================================================================
project:
  name: "colsubsidio_churn_model"
  version: "1.0.0"
  random_state: 42

# =============================================================================
# CONFIGURACIÓN DE DATOS
# =============================================================================
data:
  # Rutas de archivos (configuración flexible para notebooks y main.py)
  paths:
    raw_data: "data/raw/"           # Para main.py desde raíz
    processed_data: "data/processed/"
    outputs: "data/outputs/"
    
    # Rutas alternativas para notebooks (cuando se ejecutan desde notebooks/)
    raw_data_notebook: "../data/raw/"
    processed_data_notebook: "../data/processed/"
    outputs_notebook: "../data/outputs/"
  
  # Archivos esperados
  files:
    train: "train.csv"
    test: "test.csv"
    demograficas: "train_test_demograficas.xlsx"
    subsidios: "train_test_subsidios.xlsx"
    diccionario: "diccionario_datos.xlsx"
  
  # Configuración de carga
  encoding: "cp1252"
  separator: ";"

# =============================================================================
# CONFIGURACIÓN DE PREPROCESAMIENTO
# =============================================================================
preprocessing:
  # Variables a limpiar (formato monetario)
  financial_columns:
    - "Disponible.Avances"
    - "Limite.Avances" 
    - "Total.Intereses"
    - "Saldos.Mes.Ant"
    - "Pagos.Mes.Ant"
    - "Vtas.Mes.Ant"
    - "Limite.Cupo"
    - "Pago.del.Mes"
    - "Pago.Minimo"
    - "Vr.Mora"
    - "Vr.Cuota.Manejo"
    - "Saldo"
  
  # Valores a reemplazar en limpieza
  replacements:
    - ","
    - " "
    - "$"
    - ".00"
  
  # Manejo de valores faltantes
  missing_strategy: "fill_zero"  # fill_zero, drop, median, mean

# =============================================================================
# FEATURE ENGINEERING
# =============================================================================
feature_engineering:
  # Variables derivadas a crear
  derived_features:
    utilization_ratio:
      numerator: "Saldo"
      denominator: "Limite.Cupo"
      default_value: 0
    
    payment_behavior:
      numerator: "Pagos.Mes.Ant"
      denominator: "Saldos.Mes.Ant"
      adjustment: 1
      default_value: 0
    
    financial_stress:
      components:
        - condition: "Edad.Mora > 0"
        - condition: "Vr.Mora > 0"
        - condition: "utilization_ratio > 0.8"
    
    client_activity:
      components:
        - condition: "Vtas.Mes.Ant > 0"
        - condition: "Pagos.Mes.Ant > 0"
    
    benefits_index:
      components:
        - "cuota_monetaria"
        - "sub_vivenda"
        - "bono_lonchera"
    
    is_inactive:
      conditions:
        - "Saldo == 0"
        - "Vtas.Mes.Ant == 0"

# =============================================================================
# CONFIGURACIÓN DE MODELOS
# =============================================================================
models:
  # Random Forest (modelo principal)
  random_forest:
    n_estimators: 100
    max_depth: 10
    min_samples_split: 2
    min_samples_leaf: 1
    random_state: 42
    n_jobs: -1
  
  # Logistic Regression (modelo de comparación)
  logistic_regression:
    max_iter: 1000
    solver: "liblinear"
    random_state: 42
  
  # XGBoost (modelo experimental)
  xgboost:
    n_estimators: 100
    max_depth: 6
    learning_rate: 0.1
    subsample: 0.8
    colsample_bytree: 0.8
    random_state: 42
    eval_metric: "auc"
    early_stopping_rounds: 10

# =============================================================================
# CONFIGURACIÓN DE VALIDACIÓN
# =============================================================================
validation:
  # División de datos
  test_size: 0.2
  val_size: 0.2
  random_state: 42
  stratify: true
  
  # Cross-validation
  cv_folds: 5
  cv_scoring: "roc_auc"
  
  # Métricas a evaluar
  metrics:
    - "roc_auc"
    - "precision"
    - "recall"
    - "f1"
    - "precision_at_k"

# =============================================================================
# MANEJO DE DESBALANCE
# =============================================================================
class_balance:
  # Estrategias a probar
  strategies:
    - "class_weights"
    - "undersampling"
    - "oversampling"
  
  # Configuración de undersampling
  undersampling:
    ratio_multiplier: 10  # majority_class = minority_class * ratio_multiplier
    random_state: 42
  
  # Configuración de oversampling
  oversampling:
    minority_multiplier: 3
    random_state: 42

# =============================================================================
# SEGMENTACIÓN DE RIESGO
# =============================================================================
risk_segmentation:
  # Umbrales basados en percentiles
  thresholds:
    high_risk: 95      # Top 5%
    medium_high: 80    # Top 20%
    medium: 60         # Top 40%
    # low: < 60%       # Bottom 60%
  
  # Etiquetas de segmentos
  labels:
    high_risk: "Alto_Riesgo"
    medium_high: "Medio_Alto_Riesgo"
    medium: "Medio_Riesgo"
    low: "Bajo_Riesgo"
  
  # Configuración para precision@k
  precision_at_k: 0.1  # Top 10%

# =============================================================================
# CONFIGURACIÓN DE OUTPUTS
# =============================================================================
outputs:
  # Archivos de salida
  files:
    predictions: "final_predictions.csv"
    feature_importance: "feature_importance.csv"
    model_comparison: "model_comparison_results.csv"
    risk_segments: "risk_segmentation.csv"
    client_scores: "client_risk_segmentation.csv"
    segmentation_summary: "risk_segmentation_summary.csv"
    best_model: "best_model.pkl"
    scaler: "scaler.pkl"
    encoders: "encoders.pkl"
  
  # Formato de reportes
  reports:
    format: "html"  # html, pdf, both
    include_plots: true
    
# =============================================================================
# CONFIGURACIÓN DE LOGGING
# =============================================================================
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/model_execution.log"

# =============================================================================
# CONFIGURACIÓN ESPECÍFICA PARA NOTEBOOKS
# =============================================================================
notebook_config:
  # Configuración para cuando se ejecutan notebooks individualmente
  use_notebook_paths: true  # Usar rutas con ../
  auto_detect_environment: true  # Detectar automáticamente si estamos en notebook
  
  # Rutas específicas para notebooks
  data_paths:
    raw_data: "../data/raw/"
    processed_data: "../data/processed/"
    outputs: "../data/outputs/"
    config: "../config/"

# =============================================================================
# CONFIGURACIÓN DE EXPERIMENTACIÓN
# =============================================================================
experiments:
  # Configuración para experimentos como XGBoost
  xgboost_experiment:
    enabled: true
    compare_with_baseline: true
    baseline_model: "random_forest"
    
    # Parámetros específicos para XGBoost
    scale_pos_weight_auto: true  # Calcular automáticamente
    use_early_stopping: true
    validation_fraction: 0.2
    
    # Métricas de comparación
    comparison_metrics:
      - "auc_roc"
      - "precision"
      - "recall"
      - "f1_score"
      - "precision_at_k"
    
    # Criterios de selección del mejor modelo
    selection_criteria:
      primary_metric: "auc_roc"
      weights:
        auc_roc: 0.4
        recall: 0.35
        f1_score: 0.15
        precision: 0.1

# =============================================================================
# CONFIGURACIÓN DE PATHS DINÁMICOS
# =============================================================================
path_detection:
  # Sistema para detectar automáticamente el contexto de ejecución
  notebook_indicators:
    - "ipynb_checkpoints"
    - "In["
    - "get_ipython"
  
  # Ajuste automático de rutas
  auto_adjust_paths: true
  
  # Rutas base según contexto
  contexts:
    main_script:  # Ejecutando main.py desde raíz
      raw_data: "data/raw/"
      processed_data: "data/processed/"
      outputs: "data/outputs/"
      config: "config/"
    
    notebook:  # Ejecutando notebook desde notebooks/
      raw_data: "../data/raw/"
      processed_data: "../data/processed/"
      outputs: "../data/outputs/"
      config: "../config/"
    
    jupyter_lab:  # Ejecutando en JupyterLab
      raw_data: "../data/raw/"
      processed_data: "../data/processed/"
      outputs: "../data/outputs/"
      config: "../config/"