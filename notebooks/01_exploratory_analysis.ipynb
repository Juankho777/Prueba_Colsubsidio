{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c2f56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías cargadas exitosamente\n",
      "Análisis iniciado: 2025-08-13 14:19:59.771862\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'config\\\\model_params.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Inicializar cargador\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m DataLoader()\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Cargar todos los datasets\u001b[39;00m\n\u001b[0;32m     54\u001b[0m datasets \u001b[38;5;241m=\u001b[39m data_loader\u001b[38;5;241m.\u001b[39mload_all_datasets()\n",
      "File \u001b[1;32mc:\\Users\\38509641\\colsubsidio-churn-model\\notebooks\\..\\src\\data_loader.py:23\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, config_path)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config_path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_path \u001b[38;5;241m=\u001b[39m Path(config_path)\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_config(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_params.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_config(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_schema.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpaths\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\38509641\\colsubsidio-churn-model\\notebooks\\..\\src\\data_loader.py:32\u001b[0m, in \u001b[0;36mDataLoader._load_config\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Lee archivos YAML de configuración.\"\"\"\u001b[39;00m\n\u001b[0;32m     31\u001b[0m config_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_path \u001b[38;5;241m/\u001b[39m filename\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(config_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m yaml\u001b[38;5;241m.\u001b[39msafe_load(f)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'config\\\\model_params.yaml'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Análisis Exploratorio de Datos - Modelo de Fuga Colsubsidio\n",
    "\n",
    "Objetivo:\n",
    "- Distribución de la variable target (fuga)\n",
    "- Calidad y completitud de los datos\n",
    "- Patrones y correlaciones entre variables\n",
    "- Insights preliminares para el modelo\n",
    "\n",
    "Este script genera visualizaciones dinámicas para presentación ejecutiva.\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURACIÓN INICIAL\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "import warnings\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar plotly para notebooks\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode(connected=True)\n",
    "\n",
    "print(\"Librerías cargadas exitosamente\")\n",
    "print(f\"Análisis iniciado: {pd.Timestamp.now()}\")\n",
    "\n",
    "# =============================================================================\n",
    "# CARGA DE DATOS\n",
    "# =============================================================================\n",
    "# Agregar path del proyecto\n",
    "sys.path.append('..')\n",
    "\n",
    "# Importar módulo personalizado (con manejo de errores)\n",
    "try:\n",
    "    from src.data_loader import DataLoader\n",
    "    \n",
    "    # Inicializar cargador\n",
    "    data_loader = DataLoader()\n",
    "    \n",
    "    # Cargar todos los datasets\n",
    "    datasets = data_loader.load_all_datasets()\n",
    "    \n",
    "    # Integrar datos\n",
    "    train_integrated, test_integrated = data_loader.integrate_datasets(datasets)\n",
    "    \n",
    "    # Información básica\n",
    "    print(\"\\n=== DATASETS CARGADOS ===\")\n",
    "    for name, df in datasets.items():\n",
    "        print(f\"{name.upper()}: {len(df):,} registros x {len(df.columns)} columnas\")\n",
    "\n",
    "    print(f\"\\nTRAIN INTEGRADO: {len(train_integrated):,} registros x {len(train_integrated.columns)} columnas\")\n",
    "    print(f\"TEST INTEGRADO: {len(test_integrated):,} registros x {len(test_integrated.columns)} columnas\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"Error importando DataLoader: {e}\")\n",
    "    print(\"Usando carga de datos alternativa...\")\n",
    "    \n",
    "    # Carga alternativa de datos\n",
    "    data_path = Path(\"../data/raw\")\n",
    "    \n",
    "    # Cargar datasets principales\n",
    "    train_integrated = pd.read_csv(data_path / \"train.csv\", sep=\";\", encoding=\"cp1252\")\n",
    "    test_integrated = pd.read_csv(data_path / \"test.csv\", sep=\";\", encoding=\"cp1252\")\n",
    "    \n",
    "    # Cargar datos complementarios si existen\n",
    "    try:\n",
    "        demograficas = pd.read_excel(data_path / \"train_test_demograficas.xlsx\")\n",
    "        subsidios = pd.read_excel(data_path / \"train_test_subsidios.xlsx\")\n",
    "        \n",
    "        # Integrar datos\n",
    "        train_integrated = train_integrated.merge(demograficas, on='id', how='left')\n",
    "        train_integrated = train_integrated.merge(subsidios, on='id', how='left')\n",
    "        \n",
    "        test_integrated = test_integrated.merge(demograficas, on='id', how='left')\n",
    "        test_integrated = test_integrated.merge(subsidios, on='id', how='left')\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Archivos complementarios no encontrados, usando solo datos principales\")\n",
    "    \n",
    "    print(f\"\\nDatos cargados alternativamente:\")\n",
    "    print(f\"TRAIN: {len(train_integrated):,} registros x {len(train_integrated.columns)} columnas\")\n",
    "    print(f\"TEST: {len(test_integrated):,} registros x {len(test_integrated.columns)} columnas\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. ANÁLISIS DE LA VARIABLE TARGET\n",
    "# =============================================================================\n",
    "def analyze_target_distribution():\n",
    "    \"\"\"Analiza la distribución de la variable target (fuga).\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"1. ANÁLISIS DE LA VARIABLE TARGET\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if 'Target' not in train_integrated.columns:\n",
    "        print(\"⚠️ Variable Target no encontrada\")\n",
    "        return {}\n",
    "    \n",
    "    # Análisis de distribución del target\n",
    "    target_counts = train_integrated['Target'].value_counts()\n",
    "    target_props = train_integrated['Target'].value_counts(normalize=True)\n",
    "    \n",
    "    target_distribution = {\n",
    "        'counts': target_counts.to_dict(),\n",
    "        'proportions': target_props.to_dict(),\n",
    "        'imbalance_ratio': target_counts[0] / target_counts[1] if 1 in target_counts else None\n",
    "    }\n",
    "    \n",
    "    # Gráfico de pie interactivo\n",
    "    fig_pie = go.Figure(data=[go.Pie(\n",
    "        labels=['No Fuga (0)', 'Fuga (1)'],\n",
    "        values=[target_counts[0], target_counts[1]],\n",
    "        hole=0.4,\n",
    "        marker_colors=['#2E8B57', '#DC143C'],\n",
    "        textinfo='label+percent+value',\n",
    "        textfont_size=14\n",
    "    )])\n",
    "\n",
    "    fig_pie.update_layout(\n",
    "        title={\n",
    "            'text': 'Distribución de Fuga de Clientes UES Crédito',\n",
    "            'x': 0.5,\n",
    "            'font': {'size': 20}\n",
    "        },\n",
    "        annotations=[dict(text=f'Total<br>{target_counts.sum():,}<br>Clientes', \n",
    "                         x=0.5, y=0.5, font_size=16, showarrow=False)],\n",
    "        height=500,\n",
    "        showlegend=True\n",
    "    )\n",
    "\n",
    "    fig_pie.show()\n",
    "\n",
    "    # Mostrar estadísticas clave\n",
    "    imbalance_ratio = target_distribution.get('imbalance_ratio', 0)\n",
    "    print(f\"\\n=== ANÁLISIS DEL TARGET ===\")\n",
    "    print(f\"Total clientes: {target_counts.sum():,}\")\n",
    "    print(f\"Clientes sin fuga: {target_counts[0]:,} ({target_props[0]:.1%})\")\n",
    "    print(f\"Clientes con fuga: {target_counts[1]:,} ({target_props[1]:.1%})\")\n",
    "    print(f\"Ratio de desbalance: {imbalance_ratio:.0f}:1\")\n",
    "    if target_props[1] < 0.05:\n",
    "        print(\"⚠️ ALERTA: Desbalance extremo de clases detectado\")\n",
    "    \n",
    "    return target_distribution\n",
    "\n",
    "# =============================================================================\n",
    "# 2. ANÁLISIS DE CALIDAD DE DATOS\n",
    "# =============================================================================\n",
    "def analyze_data_quality():\n",
    "    \"\"\"Analiza la calidad y completitud de los datos.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"2. ANÁLISIS DE CALIDAD DE DATOS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Análisis de valores faltantes\n",
    "    missing_data = train_integrated.isnull().sum()\n",
    "    missing_pct = (missing_data / len(train_integrated)) * 100\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Variable': missing_data.index,\n",
    "        'Valores_Faltantes': missing_data.values,\n",
    "        'Porcentaje': missing_pct.values\n",
    "    }).query('Valores_Faltantes > 0').sort_values('Porcentaje', ascending=False)\n",
    "\n",
    "    if len(missing_df) > 0:\n",
    "        # Gráfico de barras horizontales interactivo\n",
    "        fig_missing = px.bar(\n",
    "            missing_df.head(15), \n",
    "            x='Porcentaje', \n",
    "            y='Variable',\n",
    "            orientation='h',\n",
    "            title='Variables con Valores Faltantes (Top 15)',\n",
    "            labels={'Porcentaje': 'Porcentaje de Valores Faltantes (%)', 'Variable': 'Variables'},\n",
    "            color='Porcentaje',\n",
    "            color_continuous_scale='Reds',\n",
    "            text='Porcentaje'\n",
    "        )\n",
    "        \n",
    "        fig_missing.update_traces(texttemplate='%{text:.1f}%', textposition='outside')\n",
    "        fig_missing.update_layout(\n",
    "            height=600,\n",
    "            title_font_size=18,\n",
    "            xaxis_title_font_size=14,\n",
    "            yaxis_title_font_size=14\n",
    "        )\n",
    "        \n",
    "        fig_missing.show()\n",
    "        \n",
    "        print(f\"\\n=== CALIDAD DE DATOS ===\")\n",
    "        print(f\"Variables con datos faltantes: {len(missing_df)}\")\n",
    "        print(f\"Variable con más faltantes: {missing_df.iloc[0]['Variable']} ({missing_df.iloc[0]['Porcentaje']:.1f}%)\")\n",
    "        \n",
    "        # Variables con más del 50% faltante\n",
    "        high_missing = missing_df[missing_df['Porcentaje'] > 50]\n",
    "        if len(high_missing) > 0:\n",
    "            print(f\"⚠️ Variables con >50% faltante: {list(high_missing['Variable'])}\")\n",
    "    else:\n",
    "        missing_df = pd.DataFrame()  # DataFrame vacío para uso posterior\n",
    "        print(\"✅ No se encontraron valores faltantes en el dataset\")\n",
    "    \n",
    "    return missing_df\n",
    "\n",
    "# =============================================================================\n",
    "# 3. ANÁLISIS DE VARIABLES FINANCIERAS\n",
    "# =============================================================================\n",
    "def analyze_financial_variables():\n",
    "    \"\"\"Analiza las variables financieras por target.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"3. ANÁLISIS DE VARIABLES FINANCIERAS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Variables financieras clave para análisis\n",
    "    financial_vars = ['Saldo', 'Limite.Cupo', 'Edad.Mora', 'Vr.Mora', 'Pagos.Mes.Ant', 'Vtas.Mes.Ant']\n",
    "    available_financial = [var for var in financial_vars if var in train_integrated.columns]\n",
    "\n",
    "    # Análisis estadístico por target\n",
    "    financial_stats = []\n",
    "\n",
    "    for var in available_financial:\n",
    "        # Convertir a numérico si es necesario\n",
    "        if train_integrated[var].dtype == 'object':\n",
    "            train_integrated[var] = pd.to_numeric(\n",
    "                train_integrated[var].astype(str).str.replace(',', '').str.replace(' ', ''), \n",
    "                errors='coerce'\n",
    "            )\n",
    "        \n",
    "        stats_by_target = train_integrated.groupby('Target')[var].agg(['count', 'mean', 'median', 'std']).round(0)\n",
    "        \n",
    "        for target in [0, 1]:\n",
    "            if target in stats_by_target.index:\n",
    "                financial_stats.append({\n",
    "                    'Variable': var,\n",
    "                    'Target': f'Target_{target}',\n",
    "                    'Media': stats_by_target.loc[target, 'mean'],\n",
    "                    'Mediana': stats_by_target.loc[target, 'median'],\n",
    "                    'Count': stats_by_target.loc[target, 'count']\n",
    "                })\n",
    "\n",
    "    financial_stats_df = pd.DataFrame(financial_stats)\n",
    "\n",
    "    # Crear gráfico de comparación interactivo\n",
    "    if len(financial_stats_df) > 0:\n",
    "        # Tomar top 4 variables para visualización\n",
    "        top_vars = available_financial[:4]\n",
    "        \n",
    "        fig_financial = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=top_vars,\n",
    "            specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "                   [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    "        )\n",
    "        \n",
    "        colors = ['#1f77b4', '#ff7f0e']\n",
    "        \n",
    "        for i, var in enumerate(top_vars):\n",
    "            row = (i // 2) + 1\n",
    "            col = (i % 2) + 1\n",
    "            \n",
    "            var_stats = financial_stats_df[financial_stats_df['Variable'] == var]\n",
    "            \n",
    "            if len(var_stats) > 0:\n",
    "                fig_financial.add_trace(\n",
    "                    go.Bar(\n",
    "                        x=['No Fuga', 'Fuga'],\n",
    "                        y=[var_stats[var_stats['Target'] == 'Target_0']['Media'].iloc[0] if len(var_stats[var_stats['Target'] == 'Target_0']) > 0 else 0,\n",
    "                           var_stats[var_stats['Target'] == 'Target_1']['Media'].iloc[0] if len(var_stats[var_stats['Target'] == 'Target_1']) > 0 else 0],\n",
    "                        name=var,\n",
    "                        marker_color=colors,\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    row=row, col=col\n",
    "                )\n",
    "        \n",
    "        fig_financial.update_layout(\n",
    "            title_text=\"Comparación Variables Financieras por Target (Valores Promedio)\",\n",
    "            title_font_size=18,\n",
    "            height=600,\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        fig_financial.show()\n",
    "        \n",
    "        print(\"\\n=== INSIGHTS VARIABLES FINANCIERAS ===\")\n",
    "        for var in top_vars:\n",
    "            var_data = financial_stats_df[financial_stats_df['Variable'] == var]\n",
    "            if len(var_data) >= 2:\n",
    "                no_fuga = var_data[var_data['Target'] == 'Target_0']['Media'].iloc[0]\n",
    "                fuga = var_data[var_data['Target'] == 'Target_1']['Media'].iloc[0]\n",
    "                diff_pct = ((fuga - no_fuga) / no_fuga * 100) if no_fuga != 0 else 0\n",
    "                print(f\"{var}: Fuga promedio {diff_pct:+.1f}% vs No Fuga\")\n",
    "    \n",
    "    return financial_stats_df\n",
    "\n",
    "# =============================================================================\n",
    "# 4. ANÁLISIS DEMOGRÁFICO\n",
    "# =============================================================================\n",
    "def analyze_demographic_variables():\n",
    "    \"\"\"Analiza las variables demográficas por target.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"4. ANÁLISIS DEMOGRÁFICO\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Análisis de variables demográficas\n",
    "    demographic_vars = ['segmento', 'edad', 'estrato', 'Genero']\n",
    "    available_demo = [var for var in demographic_vars if var in train_integrated.columns]\n",
    "\n",
    "    # Análisis de segmentación\n",
    "    if 'segmento' in available_demo:\n",
    "        # Crosstab para segmento vs target\n",
    "        segment_target = pd.crosstab(train_integrated['segmento'], train_integrated['Target'], normalize='columns') * 100\n",
    "        \n",
    "        # Gráfico de barras agrupadas\n",
    "        fig_segment = px.bar(\n",
    "            x=segment_target.index,\n",
    "            y=[segment_target[0], segment_target[1]],\n",
    "            title='Distribución de Segmentos por Target (%)',\n",
    "            labels={'x': 'Segmento', 'y': 'Porcentaje (%)'},\n",
    "            barmode='group',\n",
    "            color_discrete_sequence=['#2E8B57', '#DC143C']\n",
    "        )\n",
    "        \n",
    "        # Actualizar trazas para nombres\n",
    "        fig_segment.data[0].name = 'No Fuga'\n",
    "        fig_segment.data[1].name = 'Fuga'\n",
    "        \n",
    "        fig_segment.update_layout(\n",
    "            title_font_size=18,\n",
    "            height=500,\n",
    "            legend_title=\"Target\",\n",
    "            xaxis_tickangle=-45\n",
    "        )\n",
    "        \n",
    "        fig_segment.show()\n",
    "        \n",
    "        print(\"\\n=== ANÁLISIS DE SEGMENTACIÓN ===\")\n",
    "        segment_counts = train_integrated['segmento'].value_counts()\n",
    "        print(\"Distribución de clientes por segmento:\")\n",
    "        for segment, count in segment_counts.items():\n",
    "            pct = count / len(train_integrated) * 100\n",
    "            print(f\"  {segment}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "    # Análisis de edad si está disponible\n",
    "    if 'edad' in available_demo:\n",
    "        # Histograma comparativo de edad\n",
    "        fig_age = go.Figure()\n",
    "        \n",
    "        for target, label, color in [(0, 'No Fuga', '#2E8B57'), (1, 'Fuga', '#DC143C')]:\n",
    "            edad_data = train_integrated[train_integrated['Target'] == target]['edad'].dropna()\n",
    "            \n",
    "            fig_age.add_trace(go.Histogram(\n",
    "                x=edad_data,\n",
    "                name=label,\n",
    "                opacity=0.7,\n",
    "                marker_color=color,\n",
    "                nbinsx=30\n",
    "            ))\n",
    "        \n",
    "        fig_age.update_layout(\n",
    "            title='Distribución de Edad por Target',\n",
    "            title_font_size=18,\n",
    "            xaxis_title='Edad',\n",
    "            yaxis_title='Frecuencia',\n",
    "            barmode='overlay',\n",
    "            height=500\n",
    "        )\n",
    "        \n",
    "        fig_age.show()\n",
    "        \n",
    "        # Estadísticas de edad\n",
    "        edad_stats = train_integrated.groupby('Target')['edad'].agg(['mean', 'median', 'std']).round(1)\n",
    "        print(\"\\n=== ANÁLISIS DE EDAD ===\")\n",
    "        for target in [0, 1]:\n",
    "            if target in edad_stats.index:\n",
    "                label = \"No Fuga\" if target == 0 else \"Fuga\"\n",
    "                print(f\"{label}: Media {edad_stats.loc[target, 'mean']} años, Mediana {edad_stats.loc[target, 'median']} años\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. ANÁLISIS DE BENEFICIOS COLSUBSIDIO\n",
    "# =============================================================================\n",
    "def analyze_colsubsidio_benefits():\n",
    "    \"\"\"Analiza el impacto de los beneficios en la retención.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"5. ANÁLISIS DE BENEFICIOS COLSUBSIDIO\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Análisis de beneficios\n",
    "    benefit_vars = ['cuota_monetaria', 'sub_vivenda', 'bono_lonchera']\n",
    "    available_benefits = [var for var in benefit_vars if var in train_integrated.columns]\n",
    "\n",
    "    if available_benefits:\n",
    "        # Calcular índice de beneficios\n",
    "        train_integrated['total_beneficios'] = 0\n",
    "        for var in available_benefits:\n",
    "            train_integrated['total_beneficios'] += train_integrated[var].fillna(0)\n",
    "        \n",
    "        # Categorizar nivel de beneficios\n",
    "        train_integrated['nivel_beneficios'] = pd.cut(\n",
    "            train_integrated['total_beneficios'],\n",
    "            bins=[-1, 0, 1, 2, float('inf')],\n",
    "            labels=['Sin Beneficios', '1 Beneficio', '2 Beneficios', '3+ Beneficios']\n",
    "        )\n",
    "        \n",
    "        # Análisis de fuga por nivel de beneficios\n",
    "        beneficios_fuga = pd.crosstab(train_integrated['nivel_beneficios'], train_integrated['Target'], normalize='index') * 100\n",
    "        \n",
    "        # Gráfico de barras apiladas\n",
    "        fig_benefits = px.bar(\n",
    "            x=beneficios_fuga.index,\n",
    "            y=[beneficios_fuga[0], beneficios_fuga[1]],\n",
    "            title='Tasa de Fuga por Nivel de Beneficios (%)',\n",
    "            labels={'x': 'Nivel de Beneficios', 'y': 'Porcentaje (%)'},\n",
    "            color_discrete_sequence=['#2E8B57', '#DC143C']\n",
    "        )\n",
    "        \n",
    "        fig_benefits.data[0].name = 'No Fuga'\n",
    "        fig_benefits.data[1].name = 'Fuga'\n",
    "        \n",
    "        fig_benefits.update_layout(\n",
    "            title_font_size=18,\n",
    "            height=500,\n",
    "            legend_title=\"Target\"\n",
    "        )\n",
    "        \n",
    "        fig_benefits.show()\n",
    "        \n",
    "        # Estadísticas de beneficios\n",
    "        print(\"\\n=== ANÁLISIS DE BENEFICIOS ===\")\n",
    "        benefit_counts = train_integrated['nivel_beneficios'].value_counts()\n",
    "        print(\"Distribución de clientes por nivel de beneficios:\")\n",
    "        for nivel, count in benefit_counts.items():\n",
    "            pct = count / len(train_integrated) * 100\n",
    "            fuga_rate = beneficios_fuga.loc[nivel, 1] if nivel in beneficios_fuga.index else 0\n",
    "            print(f\"  {nivel}: {count:,} clientes ({pct:.1f}%) - Fuga: {fuga_rate:.1f}%\")\n",
    "    else:\n",
    "        print(\"Variables de beneficios no disponibles para análisis\")\n",
    "\n",
    "# =============================================================================\n",
    "# 6. ANÁLISIS DE CORRELACIÓN\n",
    "# ====================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
