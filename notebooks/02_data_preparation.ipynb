{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da7431a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DATASETS CARGADOS ===\n",
      "TRAIN: 50,001 registros x 22 columnas\n",
      "TEST: 5,001 registros x 20 columnas\n",
      "DEMOGRAFICAS: 55,002 registros x 10 columnas\n",
      "SUBSIDIOS: 55,002 registros x 4 columnas\n",
      "TRAIN_INTEGRATED: 50,001 registros x 34 columnas\n",
      "TEST_INTEGRATED: 5,001 registros x 32 columnas\n"
     ]
    }
   ],
   "source": [
    "# Preparación y Limpieza de Datos - Modelo de Fuga Colsubsidio\n",
    "# ==============================================================\n",
    "# \n",
    "# Objetivo: Limpiar e integrar los datasets para crear una base sólida\n",
    "# - Limpieza de variables financieras con formato monetario\n",
    "# - Manejo inteligente de valores faltantes por tipo de variable\n",
    "# - Integración robusta de múltiples fuentes de datos\n",
    "# - Validación de calidad y consistencia post-limpieza\n",
    "# - Preparación de datos listos para feature engineering\n",
    "\n",
    "# =============================================================================\n",
    "# CARGA DE DATOS\n",
    "# =============================================================================\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Ruta base de los datos\n",
    "data_path = Path(\"../data/raw\")\n",
    "\n",
    "# Cargar datasets principales\n",
    "train = pd.read_excel(data_path / \"train.xlsx\")\n",
    "test = pd.read_excel(data_path / \"test.xlsx\")\n",
    "\n",
    "# Inicializar diccionario para guardar todos los datasets cargados\n",
    "datasets = {\n",
    "    \"train\": train,\n",
    "    \"test\": test\n",
    "}\n",
    "\n",
    "#  Cargar datos complementarios\n",
    "try:\n",
    "    demograficas = pd.read_excel(data_path / \"train_test_demograficas.xlsx\")\n",
    "    subsidios = pd.read_excel(data_path / \"train_test_subsidios.xlsx\")\n",
    "    \n",
    "    datasets[\"demograficas\"] = demograficas\n",
    "    datasets[\"subsidios\"] = subsidios\n",
    "    \n",
    "    # Integrar datos en train y test\n",
    "    train_integrated = train.merge(demograficas, on=\"id\", how=\"left\") \\\n",
    "                                       .merge(subsidios, on=\"id\", how=\"left\")\n",
    "    test_integrated = test.merge(demograficas, on=\"id\", how=\"left\") \\\n",
    "                                     .merge(subsidios, on=\"id\", how=\"left\")\n",
    "    \n",
    "    datasets[\"train_integrated\"] = train_integrated\n",
    "    datasets[\"test_integrated\"] = test_integrated\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"⚠️ Archivos complementarios no encontrados. Usando solo datos principales.\")\n",
    "\n",
    "# Imprimir información de todos los datasets cargados\n",
    "print(\"\\n=== DATASETS CARGADOS ===\")\n",
    "for name, df in datasets.items():\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        print(f\"{name.upper()}: {len(df):,} registros x {len(df.columns)} columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0aa2a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Limpieza variables financieras:\n",
      "  Saldo: object → float64 (50,001 válidos)\n",
      "  Limite.Cupo: object → float64 (50,001 válidos)\n",
      "  Disponible.Avances: object → float64 (50,001 válidos)\n",
      "  Limite.Avances: object → float64 (50,001 válidos)\n",
      "  Total.Intereses: object → float64 (50,001 válidos)\n",
      "  Saldos.Mes.Ant: object → float64 (50,001 válidos)\n",
      "  Pagos.Mes.Ant: object → float64 (50,001 válidos)\n",
      "  Vtas.Mes.Ant: object → float64 (50,001 válidos)\n",
      "  Pago.del.Mes: object → float64 (50,001 válidos)\n",
      "  Pago.Minimo: object → float64 (50,001 válidos)\n",
      "  Vr.Mora: object → float64 (50,001 válidos)\n",
      "  Vr.Cuota.Manejo: object → float64 (50,001 válidos)\n",
      "  ✓ Limpieza completada - todas las variables financieras son numéricas\n",
      "\n",
      "Estadísticas principales:\n",
      "  Saldo:\n",
      "    Rango: $0 - $18,937,684\n",
      "    Promedio: $340,878\n",
      "    Ceros: 24,047 (48.1%)\n",
      "  Limite.Cupo:\n",
      "    Rango: $150,000 - $1,400,000,000\n",
      "    Promedio: $1,265,604\n",
      "    Ceros: 0 (0.0%)\n",
      "  Edad.Mora:\n",
      "    Rango: $0 - $4,050\n",
      "    Promedio: $90\n",
      "    Ceros: 41,316 (82.6%)\n",
      "  Vr.Mora:\n",
      "    Rango: $0 - $9,928,620\n",
      "    Promedio: $33,121\n",
      "    Ceros: 44,204 (88.4%)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LIMPIEZA VARIABLES FINANCIERAS TRAIN\n",
    "# =============================================================================\n",
    "\n",
    "def limpiar_financiera(serie, nombre):\n",
    "   \"\"\"Convierte formato '1 050 000.00' a float\"\"\"\n",
    "   serie_clean = serie.astype(str).str.replace(' ', '').str.replace(',', '')\n",
    "   serie_clean = serie_clean.replace('nan', np.nan)\n",
    "   return pd.to_numeric(serie_clean, errors='coerce')\n",
    "\n",
    "print(f\"\\nLimpieza variables financieras:\")\n",
    "\n",
    "train_clean = train.copy()\n",
    "\n",
    "# Variables que requieren limpieza de formato\n",
    "vars_monetarias = [\n",
    "   'Saldo', 'Limite.Cupo', 'Disponible.Avances', 'Limite.Avances',\n",
    "   'Total.Intereses', 'Saldos.Mes.Ant', 'Pagos.Mes.Ant', 'Vtas.Mes.Ant',\n",
    "   'Pago.del.Mes', 'Pago.Minimo', 'Vr.Mora', 'Vr.Cuota.Manejo'\n",
    "]\n",
    "\n",
    "for var in vars_monetarias:\n",
    "   if var in train_clean.columns:\n",
    "       antes = train_clean[var].dtype\n",
    "       train_clean[var] = limpiar_financiera(train_clean[var], var)\n",
    "       despues = train_clean[var].dtype\n",
    "       valores_validos = train_clean[var].notna().sum()\n",
    "       print(f\"  {var}: {antes} → {despues} ({valores_validos:,} válidos)\")\n",
    "\n",
    "# Verificar limpieza exitosa\n",
    "vars_texto_restantes = train_clean.select_dtypes(include=['object']).columns\n",
    "vars_financieras_texto = [v for v in vars_texto_restantes if v in vars_monetarias]\n",
    "\n",
    "if not vars_financieras_texto:\n",
    "   print(f\"  ✓ Limpieza completada - todas las variables financieras son numéricas\")\n",
    "else:\n",
    "   print(f\"  ⚠ Variables pendientes: {vars_financieras_texto}\")\n",
    "\n",
    "# Estadísticas básicas post-limpieza\n",
    "print(f\"\\nEstadísticas principales:\")\n",
    "vars_principales = ['Saldo', 'Limite.Cupo', 'Edad.Mora', 'Vr.Mora']\n",
    "\n",
    "for var in vars_principales:\n",
    "   if var in train_clean.columns:\n",
    "       stats = train_clean[var].describe()\n",
    "       ceros = (train_clean[var] == 0).sum()\n",
    "       print(f\"  {var}:\")\n",
    "       print(f\"    Rango: ${stats['min']:,.0f} - ${stats['max']:,.0f}\")\n",
    "       print(f\"    Promedio: ${stats['mean']:,.0f}\")\n",
    "       print(f\"    Ceros: {ceros:,} ({ceros/len(train_clean)*100:.1f}%)\")\n",
    "\n",
    "datasets[\"train_clean\"] = train_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "367ebe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Limpiando test...\n",
      "Train integrado: (50001, 34)\n",
      "Test integrado: (5001, 32)\n",
      "Target ratio: 34:1\n",
      "Datos preparados - listos para feature engineering\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LIMPIEZA VARIABLES FINANCIERAS TEST\n",
    "# =============================================================================\n",
    "print(f\"\\nLimpiando test...\")\n",
    "\n",
    "test_clean = test.copy()\n",
    "\n",
    "for var in vars_monetarias:\n",
    "    if var in test_clean.columns:\n",
    "        test_clean[var] = limpiar_financiera(test_clean[var], var)\n",
    "\n",
    "datasets[\"test_clean\"] = test_clean\n",
    "\n",
    "# %%\n",
    "# Integrar datos limpios con demograficas y subsidios\n",
    "train_full = train_clean.merge(demograficas, on='id', how='left').merge(subsidios, on='id', how='left')\n",
    "test_full = test_clean.merge(demograficas, on='id', how='left').merge(subsidios, on='id', how='left')\n",
    "\n",
    "print(f\"Train integrado: {train_full.shape}\")\n",
    "print(f\"Test integrado: {test_full.shape}\")\n",
    "\n",
    "# %%\n",
    "# Manejar faltantes\n",
    "train_full = train_full.fillna(0)\n",
    "test_full = test_full.fillna(0)\n",
    "\n",
    "# %%\n",
    "# Verificar y guardar\n",
    "print(f\"Target ratio: {train_full['Target'].value_counts()[0] / train_full['Target'].value_counts()[1]:.0f}:1\")\n",
    "\n",
    "train_full.to_csv('data/processed/train_prepared.csv', index=False)\n",
    "test_full.to_csv('data/processed/test_prepared.csv', index=False)\n",
    "\n",
    "print(\"Datos preparados - listos para feature engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "147624b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALIDACIÓN FINAL ===\n",
      "Dimensiones:\n",
      "  Train: (50001, 34)\n",
      "  Test: (5001, 32)\n",
      "\n",
      "Variables financieras:\n",
      "  Saldo: ✓ float64\n",
      "  Limite.Cupo: ✓ float64\n",
      "  Disponible.Avances: ✓ float64\n",
      "  Limite.Avances: ✓ float64\n",
      "  Total.Intereses: ✓ float64\n",
      "  Saldos.Mes.Ant: ✓ float64\n",
      "  Pagos.Mes.Ant: ✓ float64\n",
      "  Vtas.Mes.Ant: ✓ float64\n",
      "  Pago.del.Mes: ✓ float64\n",
      "  Pago.Minimo: ✓ float64\n",
      "  Vr.Mora: ✓ float64\n",
      "  Vr.Cuota.Manejo: ✓ float64\n",
      "\n",
      "Target:\n",
      "  No Fuga: 48,589\n",
      "  Fuga: 1,412\n",
      "  Ratio: 34:1\n",
      "\n",
      "Faltantes:\n",
      "  Train: 0\n",
      "  Test: 0\n",
      "\n",
      "Consistencia columnas: ✗\n",
      "  Solo en train: {'Retencion'}\n",
      "  Solo en test: set()\n",
      "\n",
      "⚠️ REVISAR ISSUES\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VALIDACION FINAL\n",
    "# =============================================================================\n",
    "print(\"=== VALIDACIÓN FINAL ===\")\n",
    "\n",
    "# 1. Verificar dimensiones\n",
    "print(f\"Dimensiones:\")\n",
    "print(f\"  Train: {train_full.shape}\")\n",
    "print(f\"  Test: {test_full.shape}\")\n",
    "\n",
    "# 2. Verificar variables financieras son numéricas\n",
    "financial_check = []\n",
    "for var in vars_monetarias:\n",
    "   if var in train_full.columns:\n",
    "       is_numeric = train_full[var].dtype in ['int64', 'float64']\n",
    "       financial_check.append(f\"  {var}: {'✓' if is_numeric else '✗'} {train_full[var].dtype}\")\n",
    "\n",
    "print(f\"\\nVariables financieras:\")\n",
    "for check in financial_check:\n",
    "   print(check)\n",
    "\n",
    "# 3. Verificar target\n",
    "target_dist = train_full['Target'].value_counts()\n",
    "print(f\"\\nTarget:\")\n",
    "print(f\"  No Fuga: {target_dist[0]:,}\")\n",
    "print(f\"  Fuga: {target_dist[1]:,}\")\n",
    "print(f\"  Ratio: {target_dist[0]/target_dist[1]:.0f}:1\")\n",
    "\n",
    "# 4. Verificar faltantes\n",
    "print(f\"\\nFaltantes:\")\n",
    "print(f\"  Train: {train_full.isnull().sum().sum()}\")\n",
    "print(f\"  Test: {test_full.isnull().sum().sum()}\")\n",
    "\n",
    "# 5. Verificar consistencia columnas (sin target)\n",
    "train_cols = set(train_full.columns) - {'Target'}\n",
    "test_cols = set(test_full.columns)\n",
    "consistent = train_cols == test_cols\n",
    "\n",
    "print(f\"\\nConsistencia columnas: {'✓' if consistent else '✗'}\")\n",
    "if not consistent:\n",
    "   print(f\"  Solo en train: {train_cols - test_cols}\")\n",
    "   print(f\"  Solo en test: {test_cols - train_cols}\")\n",
    "\n",
    "print(f\"\\n{' VALIDACIÓN EXITOSA' if consistent and train_full.isnull().sum().sum() == 0 else '⚠️ REVISAR ISSUES'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36a74e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train después: (50001, 33)\n",
      "Test: (5001, 32)\n",
      "Consistencia: ✓\n",
      " PREPARACIÓN COMPLETADA\n",
      "Train final: (50001, 33)\n",
      "Test final: (5001, 32)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ELIMINAR VARIABLES INNECESARIAS\n",
    "# =============================================================================\n",
    "train_full = train_full.drop(['Retencion'], axis=1)\n",
    "\n",
    "print(f\"Train después: {train_full.shape}\")\n",
    "print(f\"Test: {test_full.shape}\")\n",
    "\n",
    "# Verificar consistencia\n",
    "train_cols = set(train_full.columns) - {'Target'}\n",
    "test_cols = set(test_full.columns)\n",
    "print(f\"Consistencia: {'✓' if train_cols == test_cols else '✗'}\")\n",
    "\n",
    "# %%\n",
    "# Guardar versión final\n",
    "train_full.to_csv('data/processed/train_prepared.csv', index=False)\n",
    "test_full.to_csv('data/processed/test_prepared.csv', index=False)\n",
    "\n",
    "print(\" PREPARACIÓN COMPLETADA\")\n",
    "print(f\"Train final: {train_full.shape}\")\n",
    "print(f\"Test final: {test_full.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7337f7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CORRECCIÓN FECHAS (según diccionario) ===\n",
      "\n",
      "Fecha.Expedicion:\n",
      "  Tipo actual: object\n",
      "  Muestra antes: [datetime.datetime(2006, 4, 11, 0, 0), '17/08/2007']\n",
      "  Tipo después: datetime64[ns]\n",
      "  Muestra después: [Timestamp('2006-04-11 00:00:00'), Timestamp('2007-08-17 00:00:00')]\n",
      "  Nulos: 0\n",
      "\n",
      "Fecha.Proceso:\n",
      "  Tipo actual: object\n",
      "  Muestra antes: [datetime.datetime(2018, 1, 4, 0, 0), datetime.datetime(2018, 1, 4, 0, 0)]\n",
      "  Tipo después: datetime64[ns]\n",
      "  Muestra después: [Timestamp('2018-01-04 00:00:00'), Timestamp('2018-01-04 00:00:00')]\n",
      "  Nulos: 0\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CORRECCIÓN FECHAS SEGÚN DICCIONARIO\n",
    "# =============================================================================\n",
    "print(\"=== CORRECCIÓN FECHAS (según diccionario) ===\")\n",
    "\n",
    "fecha_cols = ['Fecha.Expedicion', 'Fecha.Proceso']\n",
    "\n",
    "for col in fecha_cols:\n",
    "    if col in train_full.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Tipo actual: {train_full[col].dtype}\")\n",
    "        print(f\"  Muestra antes: {train_full[col].head(2).tolist()}\")\n",
    "        \n",
    "        # Conversión según diccionario\n",
    "        train_full[col] = pd.to_datetime(train_full[col], errors='coerce', dayfirst=True)\n",
    "        test_full[col] = pd.to_datetime(test_full[col], errors='coerce', dayfirst=True)\n",
    "        \n",
    "        print(f\"  Tipo después: {train_full[col].dtype}\")\n",
    "        print(f\"  Muestra después: {train_full[col].head(2).tolist()}\")\n",
    "        print(f\"  Nulos: {train_full[col].isnull().sum()}\")\n",
    "\n",
    "# %%\n",
    "# Guardar con fechas corregidas\n",
    "train_full.to_csv('data/processed/train_prepared.csv', index=False)\n",
    "test_full.to_csv('data/processed/test_prepared.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e1b99ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRATAMIENTO DE OUTLIERS ===\n",
      "Tratando outliers en train...\n",
      "  Saldo: 500 outliers tratados (cap en $3,118,276)\n",
      "  Limite.Cupo: 499 outliers tratados (cap en $8,950,000)\n",
      "  Pago.del.Mes: 500 outliers tratados (cap en $281,700)\n",
      "  Vr.Mora: 500 outliers tratados (cap en $650,521)\n",
      "  Disponible.Avances: 500 outliers tratados (cap en $4,066,641)\n",
      "\n",
      "Tratando outliers en test...\n",
      "  Saldo: 50 outliers tratados (cap en $2,895,680)\n",
      "  Limite.Cupo: 50 outliers tratados (cap en $8,300,000)\n",
      "  Pago.del.Mes: 50 outliers tratados (cap en $200,000)\n",
      "  Vr.Mora: 50 outliers tratados (cap en $576,696)\n",
      "  Disponible.Avances: 50 outliers tratados (cap en $4,000,000)\n",
      "\n",
      " Outliers tratados - datos más robustos para modelado\n",
      " Datos re-guardados con outliers tratados\n",
      "Archivos actualizados para feature engineering\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TRATAMIENTO DE OUTLIERS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=== TRATAMIENTO DE OUTLIERS ===\")\n",
    "\n",
    "def tratar_outliers_financieros(df):\n",
    "   df_clean = df.copy()\n",
    "   \n",
    "   # Variables financieras principales\n",
    "   vars_financieras = ['Saldo', 'Limite.Cupo', 'Pago.del.Mes', 'Vr.Mora', 'Disponible.Avances']\n",
    "   \n",
    "   for var in vars_financieras:\n",
    "       if var in df_clean.columns:\n",
    "           # Calcular percentiles\n",
    "           p99 = df_clean[var].quantile(0.99)\n",
    "           outliers_antes = (df_clean[var] > p99).sum()\n",
    "           \n",
    "           # Aplicar cap en P99\n",
    "           df_clean[var] = np.where(df_clean[var] > p99, p99, df_clean[var])\n",
    "           \n",
    "           print(f\"  {var}: {outliers_antes} outliers tratados (cap en ${p99:,.0f})\")\n",
    "   \n",
    "   return df_clean\n",
    "\n",
    "# Aplicar a ambos datasets\n",
    "print(\"Tratando outliers en train...\")\n",
    "train_full = tratar_outliers_financieros(train_full)\n",
    "\n",
    "print(\"\\nTratando outliers en test...\")\n",
    "test_full = tratar_outliers_financieros(test_full)\n",
    "\n",
    "print(\"\\n Outliers tratados - datos más robustos para modelado\")\n",
    "\n",
    "# %%\n",
    "# RE-GUARDAR DATOS CON OUTLIERS TRATADOS\n",
    "train_full.to_csv('data/processed/train_prepared.csv', index=False)\n",
    "test_full.to_csv('data/processed/test_prepared.csv', index=False)\n",
    "\n",
    "print(\" Datos re-guardados con outliers tratados\")\n",
    "print(\"Archivos actualizados para feature engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "382dc7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GUARDAR DATOS PREPARADOS\n",
    "# =============================================================================\n",
    "train_full.to_csv('data/processed/train_prepared.csv', index=False)\n",
    "test_full.to_csv('data/processed/test_prepared.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
